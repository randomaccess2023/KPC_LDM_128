{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db20d4c",
   "metadata": {},
   "source": [
    "# <center>This `.ipynb` file contains the code for generating samples by utlizing latent features of the training images as a conditioning mechanism</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271c105",
   "metadata": {},
   "source": [
    "### 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from pfiles.unet_cond_base import UNet\n",
    "from pfiles.vqvae import VQVAE\n",
    "from pfiles.linear_noise_scheduler import LinearNoiseScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30a6c6",
   "metadata": {},
   "source": [
    "### 2. Define the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device is:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a4733",
   "metadata": {},
   "source": [
    "### 3. Set different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cba90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 765\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73662f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead38aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_batch_size = 1\n",
    "rgb_input = 3\n",
    "z_channels = 16\n",
    "n_clusters = 14 # change it to 10, 11, 12, 13, 15, or 16 for other partitions\n",
    "\n",
    "image_size = 128\n",
    "num_samples = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704c0b9",
   "metadata": {},
   "source": [
    "### 4. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a604a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_src = '/project/dsc-is/nono/Documents/kpc/dat0'\n",
    "data_src = 'slice128_Block2_11K.npy'\n",
    "\n",
    "print(os.path.join(dir_src, data_src))\n",
    "\n",
    "kpc_dataset = np.load(os.path.join(dir_src, data_src))\n",
    "kpc_dataset = kpc_dataset[:, 0, :, :, :]\n",
    "\n",
    "print(kpc_dataset.shape)\n",
    "N_SAMPLE, HEIGHT, WIDTH, CHANNELS = kpc_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67758ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_range = np.arange(N_SAMPLE)\n",
    "split = np.array_split(index_range, 11)\n",
    "test_dataset = split[10]\n",
    "training_dataset = np.setdiff1d(index_range, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of the training dataset:', len(training_dataset))\n",
    "print('Length of the test dataset:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93011888",
   "metadata": {},
   "source": [
    "### 5. Custom functions for extracting batches of samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_list(idx, n_batch=10, batch_size=None, shuffle=True):\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    if batch_size is not None:\n",
    "        n_batch = len(idx) // batch_size\n",
    "    batch_list = np.array_split(idx, n_batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ea4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "def generate_batch(idx, kpc_dataset):\n",
    "    tmp = []\n",
    "    for i in idx:\n",
    "        xxx = transform(kpc_dataset[i])\n",
    "        tmp.append(xxx)\n",
    "    xxx_batch = torch.stack(tmp, dim=0)\n",
    "    return xxx_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e54c8",
   "metadata": {},
   "source": [
    "### 6. Set up directory for saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'models_14'\n",
    "\n",
    "if not os.path.exists(task_name):\n",
    "    os.mkdir(task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6976c2",
   "metadata": {},
   "source": [
    "### 7. Neural network for deep learning-based clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('conv1', nn.Conv2d(in_channels=z_channels, out_channels=128, kernel_size=4, stride=2,\n",
    "                                                      padding=1))\n",
    "        self.classifier.add_module('bnor1', nn.BatchNorm2d(num_features=128, affine=True, track_running_stats=True))\n",
    "        self.classifier.add_module('lrel1', nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "        self.classifier.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, stride=2, padding=1))\n",
    "        self.classifier.add_module('bnor2', nn.BatchNorm2d(num_features=128, affine=True, track_running_stats=True))\n",
    "        self.classifier.add_module('lrel2', nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "        self.classifier.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, stride=2, padding=1))\n",
    "        self.classifier.add_module('lrel3', nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "        self.classifier.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=n_clusters, kernel_size=4, stride=1,\n",
    "                                                      padding=0))\n",
    "        self.classifier.add_module('lrel4', nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "        \n",
    "    def forward(self, lat):\n",
    "        out = self.classifier(lat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6191249",
   "metadata": {},
   "source": [
    "### 8. Instantiate `UNet`, `VQVAE`, and `Classifier` architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(im_channels=z_channels, cls=n_clusters).to(device)\n",
    "model.eval()\n",
    "print('Loaded unet finetuning2 checkpoint')\n",
    "model.load_state_dict(torch.load(os.path.join(task_name, 'unet_finetuning2_ckpt_20250128_70_14.pth'), map_location=device,\n",
    "                                     weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23703403",
   "metadata": {},
   "outputs": [],
   "source": [
    "vq_vae = VQVAE(im_channels=rgb_input).to(device)\n",
    "vq_vae.eval()\n",
    "print('Loaded vq_vae checkpoint')\n",
    "vq_vae.load_state_dict(torch.load(os.path.join('../kpc_ldm', 'vqvae_autoencoder_ckpt.pth'), map_location=device,\n",
    "                                  weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cl = Classifier().to(device)\n",
    "model_cl.eval()\n",
    "print('Loaded model_cl finetuning2 checkpoint')\n",
    "model_cl.load_state_dict(torch.load(os.path.join(task_name, 'classifier_finetuning2_ckpt_20250128_70_14.pth'),\n",
    "                                    map_location=device, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2067d8a",
   "metadata": {},
   "source": [
    "### 9. Custom function to conditionally generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730af921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_sample(model, scheduler, vq_vae):\n",
    "    \n",
    "    im_size = image_size // 2 ** sum([True, True])\n",
    "    xt = torch.randn((num_samples, z_channels, im_size, im_size)).to(device)\n",
    "    \n",
    "    for i in tqdm(reversed(range(num_timesteps))):\n",
    "        \n",
    "        t = (torch.ones((xt.shape[0],)) * i).long().to(device)\n",
    "        noise_pred = model(xt, t, training_cond_input)\n",
    "        \n",
    "        xt, x0_pred = scheduler.sample_prev_timestep(xt, noise_pred, torch.as_tensor(i).to(device))\n",
    "        \n",
    "        if i==0:\n",
    "            ims = vq_vae.decode(xt)\n",
    "        else:\n",
    "            ims = xt\n",
    "            \n",
    "    return ims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c906ecb",
   "metadata": {},
   "source": [
    "### 10. Instantiate `linear` scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df7dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LinearNoiseScheduler(num_timesteps=num_timesteps, beta_start=beta_start, beta_end=beta_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e6f7b3",
   "metadata": {},
   "source": [
    "### 11. Prepare to generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eec388",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_list = make_batch_list(training_dataset, batch_size=select_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d9585",
   "metadata": {},
   "source": [
    "### 12. Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_batch_list)):\n",
    "    training_xxx = generate_batch(training_batch_list[i], kpc_dataset)\n",
    "    training_xxx = training_xxx.to(device)\n",
    "    training_im, _ = vq_vae.encode(training_xxx)\n",
    "    training_out_cl = model_cl(training_im)\n",
    "    training_cond_input = torch.argmax(training_out_cl.reshape((-1, n_clusters)), dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gen_ims = cond_sample(model=cond_unet, scheduler=scheduler, vq_vae=vq_vae)\n",
    "        \n",
    "    gen_ims = torch.clamp(gen_ims, min=0., max=1.).detach().cpu()\n",
    "    print(i+1)\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(gen_ims.squeeze().permute(1, 2, 0))\n",
    "    plt.axis(False)\n",
    "    plt.savefig(f'gen_14/{i+1}.jpg', dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
